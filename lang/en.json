{
  "language_name": "English",
  "language_code": "en",
  "app_title": "MSN-AI",
  "app_description": "MSN-AI AI Assistant",
  "status": {
    "online": "Online",
    "away": "Away",
    "busy": "Busy",
    "invisible": "Invisible",
    "connecting": "Connecting...",
    "connected": "Connected",
    "disconnected": "Disconnected"
  },
  "menu": {
    "new_chat": "New Chat",
    "settings": "Settings",
    "export_import": "Export/Import",
    "help": "Help",
    "info": "Information"
  },
  "buttons": {
    "send": "Send",
    "cancel": "Cancel",
    "close": "Close",
    "save": "Save",
    "delete": "Delete",
    "export": "Export",
    "import": "Import",
    "apply": "Apply",
    "test_connection": "Test Connection",
    "search": "Search",
    "clear": "Clear",
    "copy": "üìã Copy to Chat",
    "update": "Update",
    "order_history": "Order History",
    "export_selected": "Export Selected",
    "nudge": "Send Nudge",
    "voice_input": "Voice Input",
    "clear_chat": "Clear Current Chat",
    "increase_font": "Increase Size",
    "decrease_font": "Decrease Size",
    "upload_file": "Attach File",
    "export_chat": "Export Chat",
    "print_chat": "Print Chat",
    "search_chat": "Search in Chat",
    "create": "Create Room",
    "close_chat": "Close Chat",
    "stop_response": "Stop AI Response"
  },
  "tooltips": {
    "new_chat": "Create a new chat",
    "new_room": "Create an expert room",
    "settings": "AI model settings",
    "nudge": "Send a nudge",
    "emoticon_natural": "Natural emoticons",
    "emoticon_love": "Love emoticons",
    "voice_input": "Voice Dictation",
    "voice_input_stop": "Stop Dictation",
    "upload_file": "Attach text file",
    "upload_pdf_file": "Attach PDF file",
    "upload_image_file": "Attach image file",
    "text_format": "Text format (Bold, Italic, Underline)",
    "generate_prompt": "Prompt Generator - Create structured prompts",
    "manage_prompts": "Prompt Manager - Manage saved prompts",
    "increase_font": "Increase Font Size",
    "decrease_font": "Decrease font size",
    "export_chat": "Export current chat to text file",
    "print_chat": "Print current chat",
    "search_chat": "Search in current chat",
    "close_chat": "Close current chat and create a new one",
    "chats_export": "Export chats",
    "chats_import": "Import chats",
    "delete_attachment": "Delete file",
    "download_pdf": "Download file",
    "download_txt": "Download file",
    "download_image": "Download file"
  },
  "settings": {
    "title": "AI Model Settings",
    "tab_general": "General",
    "tab_connection": "Connection",
    "tab_advanced": "Advanced",
    "sounds_enabled": "Sounds enabled",
    "ollama_server": "Ollama Server",
    "ollama_server_description": "Ollama server address. Leave empty for auto-detection.",
    "select_model": "AI Model",
    "model_description": "Model to be used for new chats. Existing chats keep their model.",
    "no_models": "No models installed",
    "no_connection": "No connection - Check settings",
    "api_timeout": "Timeout (ms)",
    "notify_status_changes": "Notify status changes to AI",
    "notify_status_changes_description": "When you change your status (Online, Away, Busy, Invisible), the AI will be automatically notified in the active chat.",
    "rate_limit": "Interval between requests",
    "rate_limit_description": "Minimum time between requests to Ollama. Increase if you get 429 (Too Many Requests) errors.",
    "max_tokens": "Maximum tokens in response",
    "max_tokens_description": "Maximum number of tokens the model can generate in a response. Increase if responses are cut off.",
    "language": "Interface Language",
    "language_description": "Language in which menus, buttons and system messages will be displayed.",
    "connection_success": "Connection successful!\n\nAvailable models: {count}\n\nServer: {server}",
    "connection_failed": "Could not connect",
    "settings_saved": "Settings saved",
    "testing_connection": "Testing...",
    "group_chat_system_prompt": "System Prompt for Group Chat Rooms",
    "group_chat_system_prompt_description": "Instruction template sent to each AI model in group rooms. Variables: {{MODEL_NAME}} (participant name), {{PARTICIPANT_LIST}} (list of participants).",
    "reset_system_prompt": "üîÑ Reset",
    "reset_system_prompt_title": "Restore default template",
    "default_group_chat_system_prompt": "SYSTEM:\n  - MULTI-MODEL GROUP CHAT ACTIVATED.\n  - This conversation is a group chat with multiple AI models.\n\nROLE:\n  - You are {{MODEL_NAME}}, an LLM participant in a multi-agent group chat room. Your function is to respond with precision, authenticity and respect, following the formatting rules and limits indicated below.\n\nCONTEXT:\n  - You are participating in a MULTI-AGENT GROUP CHAT.\n  - Group context: We are in a multiple collaborative session where several AI models participate simultaneously. Each one functions independently but shares this common space.\n  - Nature: You are in a simultaneous conversation with multiple instances of AI models and/or users. You have access to the shared message history.\n  - Expectation: Act as an individual participant within this collaborative group.\n  - List of ACTIVE PARTICIPANTS: {{PARTICIPANT_LIST}}\n  - Interlocutor role: User who coordinates a conversation with several simultaneous models.\n  - Main description: Group chat room where several LLMs can intervene in any order.\n  - Concrete situation: Each model receives the complete history and can respond when it considers useful within the limits of its specific instance.\n  - Desired impact: Maintain coherence, avoid duplicates, respect identities.\n\nAUDIENCE:\n  - Adults over 18 years old.\n\nTASKS:\n  1. TASK 1: Read the complete history and detect if your handle already appears in the participant list.\n  2. TASK 2: Verify that your own message starts exactly with `[{{MODEL_NAME}}]:`.\n  3. TASK 3: Self-review that your response is the most accurate to the topic being developed in the group chat room.\n  4. TASK 4: (Optional) Request clarification from the user if critical data is missing.\n  5. TASK 5: Issue the final response and stop; do not continue generating more turns on your own unless you have something to observe or share for the benefit of all participants.\n\nINSTRUCTIONS:\n  - MANDATORY IDENTIFICATION. Before responding, verify if your exact identifier appears in the active participant list. Only respond if you are present in this list.\n  - RESPONSE PROTOCOL: Start EVERY message with your identifier in brackets: `[{{MODEL_NAME}}]:` Do not respond on behalf of other models. Do not simulate being another model from the list. Maintain awareness that other models are also reading and responding.\n  - GROUP AWARENESS: Read all history before responding. Recognize that you are an individual instance in a collaborative environment. Do not assume that other models share your memory or internal context. Be aware that your responses are visible to all participants.\n  - WHEN TO RESPOND: Respond only when specifically addressed or when your expertise is relevant. Avoid interrupting conversations between other models unless necessary. If several models respond simultaneously, it is expected and valid behavior.\n  - CONFIRM YOUR UNDERSTANDING: by starting your first response with: `[{{MODEL_NAME}}] - Group context confirmed`\n  - Maintain coherence with chat history.\n  - Collaborate by complementing responses when appropriate.\n  - Independence: Remember that your response is generated by your individual instance. There is no \"telepathic\" communication or group consensus outside the visible text in this chat.\n  - Behavior instructions:\n    1. Recognize the chat nature: Each message comes from a different user. If the content of a message is directed to you (for example, contains your alias or name), respond directly. If the message is general, you can respond informatively, offering help to anyone who needs it.\n    2. Self-denomination: When referring to yourself, always use your alias `[{{MODEL_NAME}}]`. Do not use phrases like \"I, the model\" or \"this model\"; use your alias for clarity.\n    3. Mention others: When addressing a user or mentioning someone, use their alias as it appears in the participant list (e.g. `@PARTICIPANT_1`).\n    4. Maintain group coherence: If the dialogue requires coordination between several assistants, clearly indicate who you are responding to and why. Avoid responding to messages not directed to you, unless it is a clarification that benefits the group or is a query directed to all participants. Avoid repeating information already shared by others.\n    5. Output format: Keep responses concise and clear. When necessary, use light markup (e.g., **bold**, *italic* or `code`) to improve readability, but without overdoing complexity. Format: Markdown; in the language active in the group chat room.\n\nCLARIFICATION:\n  - Authorize the model to request data if it detects gaps? Yes, but only brief questions per turn.\n\nREFINEMENT:\n  - Planned iterations? Yes, up to 7 rounds if the user requests adjustments.\n  - Focus: main topic being developed in the group chat room.\n  - Quality criteria: Relevance ‚â• 99%, 0 violations, correct handle.\n  - Self-review accuracy? Yes, always before final output.\n\nBOUNDARIES:\n  - You receive the complete information Conversation history in each turn.\n  - You can only respond when you have something useful to contribute; silence is acceptable.\n  - When speaking, start with `[{{MODEL_NAME}}]:` so others can identify who is speaking.\n  - Never impersonate someone else; use the name that matches your entry in the participant list.\n  - Do not assume consensus or private conversations; each call is stateless.\n  - If you need to address a colleague, use their exact username as it appears in the participant list.\n  - Negatives: Avoid hallucinations.\n  - Prohibited: unnecessary technicalities.\n  - Mandatory rules: visible handle.\n  - Length limit: Stop when reaching TASK 5.\n\nEMPATHY:\n  - Tone: close, technical and playful.\n\nCONSEQUENCES:\n  - If you fail to comply with format or limits, the user will ask for retry; after three failures the model will be changed.\n\nEXAMPLE:\n  - User input: ¬´What do you think about...?¬ª\n  - Correct output: `[{{MODEL_NAME}}]:` According to my analysis..."
  },
  "export_import": {
    "export_title": "Export Chats",
    "export_description": "Select a previously exported JSON chat file.",
    "export_description_full": "Export all your chats in JSON format for backup or migration.",
    "export_all": "Export all chats",
    "export_selected": "Export selected chats",
    "export_selected_info": "Mark chats in the list using the avatar icon.",
    "import_title": "Import Chats",
    "import_description": "Select a previously exported JSON chat file.",
    "import_button": "Import",
    "no_selected": "No chats selected for export.",
    "download_chats": "Download Chats"
  },
  "import_conflict": {
    "title": "Duplicate Chat Detected",
    "chat_title": "Title",
    "model": "Model",
    "existing_count": "Existing chat",
    "imported_count": "Chat to import",
    "messages_suffix": "message(s)",
    "warning": "WARNING: The chat to import has FEWER messages. Replacing would cause data loss.",
    "warning_blocked": "CANNOT REPLACE: Data would be lost.",
    "question": "What would you like to do?",
    "option_merge": "Merge",
    "option_merge_desc": "Combine both chats keeping all messages",
    "option_replace": "Replace",
    "option_replace_desc": "Replace existing chat with imported one",
    "option_skip": "Skip",
    "option_skip_desc": "Do not import this chat",
    "option_skip_all": "Skip all",
    "option_skip_all_desc": "Skip this and remaining conflicts",
    "counter": "Conflict {current} of {total}",
    "auto_skipped": "This chat will be skipped automatically."
  },
  "import_summary": {
    "title": "Import Completed",
    "imported": "chat(s) imported",
    "merged": "chat(s) merged",
    "replaced": "chat(s) replaced",
    "skipped": "chat(s) skipped",
    "no_changes": "No changes were made."
  },
  "context_menu": {
    "edit_title": "Edit title",
    "export_chat": "Export chat",
    "delete_chat": "Delete chat"
  },
  "edit_title": {
    "title": "Edit chat title",
    "label": "New title:",
    "placeholder": "Enter the new chat title",
    "success": "Title updated successfully",
    "error": "Title cannot be empty"
  },
  "prompt_generator": {
    "title": "Prompt Generator",
    "role": "LLM Role",
    "role_placeholder": "Define the LLM role (e.g., 'You are an expert assistant in...')",
    "context": "Context",
    "context_placeholder": "Describe the context and specific situation",
    "audience": "Audience",
    "audience_placeholder": "Specify the target audience",
    "tasks": "Tasks (one per line)",
    "tasks_placeholder": "TASK 1: Description of the first task\nTASK 2: Description of the second task",
    "instructions": "Instructions",
    "instructions_placeholder": "Format, style, language and other technical parameters",
    "empathy": "Empathy and Tone",
    "empathy_placeholder": "Define the emotional tone and empathy level",
    "clarification": "Clarification",
    "clarification_placeholder": "Instructions on how to ask for user clarifications",
    "refinement": "Refinement",
    "refinement_placeholder": "Instructions to iterate and improve responses",
    "boundaries": "Boundaries",
    "boundaries_placeholder": "Restrictions and boundaries to consider",
    "consequences": "Consequences",
    "consequences_placeholder": "Consequences of not following instructions",
    "example": "Examples",
    "example_placeholder": "Examples of expected input and output",
    "generate": "‚ú® Generate Prompt",
    "result_title": "Generated Prompt (Markdown)",
    "save": "‚≠ê Save Prompt",
    "save_prompt_title": "Save Prompt",
    "prompt_name": "Prompt Name",
    "prompt_name_placeholder": "Enter a descriptive name",
    "prompt_description": "Description (optional)",
    "prompt_description_placeholder": "Brief description of purpose",
    "prompt_category": "Category (optional)",
    "prompt_category_placeholder": "e.g., Development, Marketing, Education",
    "prompt_tags": "Tags (optional)",
    "prompt_tags_placeholder": "Comma separated: tag1, tag2, tag3",
    "saved_success": "Prompt saved successfully",
    "updated_success": "Prompt updated successfully",
    "copy_success": "Prompt copied to chat",
    "name_required": "Prompt name is required"
  },
  "prompt_manager": {
    "title": "My Saved Prompts",
    "search_placeholder": "Search prompts...",
    "all_categories": "All categories",
    "refresh": "Refresh list",
    "no_prompts_title": "üìù No saved prompts",
    "no_prompts_message": "Generate a prompt and click '‚≠ê Save Prompt' to start your collection.",
    "export_all": "üì§ Export All",
    "export_all_tooltip": "Export all prompts to a JSON file",
    "import": "üì• Import",
    "import_tooltip": "Import prompts from a JSON file",
    "delete_all": "üóëÔ∏è Delete All",
    "delete_all_tooltip": "Delete all saved prompts",
    "delete_all_confirm": "Are you sure you want to delete all saved prompts? This action cannot be undone.",
    "use_prompt": "üìù Use",
    "view_prompt": "üëÅÔ∏è View",
    "edit_prompt": "‚úèÔ∏è Edit",
    "delete_prompt": "üóëÔ∏è Delete",
    "export_prompt": "üì§ Export",
    "load_to_form": "üìù Load to Form",
    "delete_confirm": "Are you sure you want to delete this prompt?",
    "export_success": "Prompts exported successfully",
    "import_success": "Prompts imported successfully",
    "delete_success": "Prompt deleted successfully",
    "no_export": "No prompts to export",
    "prompts_count": "{count} prompts saved",
    "prompts_found": "{count} prompts found",
    "prompts_in_category": "{count} prompts in this category",
    "no_results": "No prompts found",
    "try_another_search": "Try another search",
    "no_prompts_in_category": "No prompts in this category",
    "loaded_to_form": "Prompt loaded to form",
    "edit_mode": "Edit mode activated. Modify the fields and generate the updated prompt.",
    "editing_prompt": "Editing Prompt",
    "edit_cancelled": "Edit cancelled",
    "general_info": "General Information",
    "date": "Date",
    "import_error": "Error importing prompts",
    "prompt_not_found": "Prompt not found",
    "export_single_success": "Prompt exported successfully",
    "delete_all_success": "All prompts deleted"
  },
  "delete_chat": {
    "title": "Delete chat",
    "message": "Are you sure you want to delete this chat? This action cannot be undone.",
    "confirm": "Delete",
    "cancel": "Cancel"
  },
  "search_chat": {
    "title": "Search in Chat",
    "placeholder": "Type your search...",
    "search_button": "Search",
    "clear_button": "Clear Highlight"
  },
  "info": {
    "title": "About MSN-AI",
    "version": "Version",
    "description": "AI chat system inspired by Windows Live Messenger.",
    "features": "Main features:",
    "feature_1": "Real-time chat with AI models (Ollama)",
    "feature_2": "Nostalgic MSN Messenger style interface",
    "feature_3": "Multiple chats and models management",
    "feature_4": "Conversation export and import",
    "feature_5": "Multilanguage support",
    "feature_6": "Emoticons and text formatting",
    "credits": "Developed with ‚ù§Ô∏è for the community",
    "contact_title": "Contact",
    "contact_thanks": "Thanks for your interest in <strong>MSN-AI</strong>.",
    "contact_name": "Name",
    "contact_email": "Email",
    "contact_project": "Project",
    "contact_message_1": "This is a personal open source project. Please be patient if the response is not immediate.",
    "contact_message_2": "Before contacting, make sure you have reviewed the documentation and source code in the GitHub repository."
  },
  "chat": {
    "select_chat": "Select a chat",
    "welcome_message": "Select a chat from the list or create a new one to begin.",
    "new_chat_title": "New chat {number}",
    "no_chats": "No chats. Create a new one.",
    "no_models": "No models installed. Install models in Ollama.",
    "model_info": "Model: {model} - {count} messages",
    "ai_thinking": "AI is thinking",
    "you": "You",
    "ai": "AI",
    "system": "system",
    "response_stopped": "Response stopped by user",
    "response_stopped_before": "Response stopped before starting",
    "search_placeholder": "Search chats...",
    "message_placeholder": "Type your message here...",
    "show_more": "Show {count} more...",
    "show_less": "Show less",
    "attachments_title": "Attached files",
    "attachments_context_header": "ATTACHED FILES TO CHAT",
    "attachments_context_footer": "END OF ATTACHED FILES"
  },
  "messages": {
    "status_changed": "I have changed my status to {status}. {message}",
    "status_online": "I'm available to chat.",
    "status_away": "I'm away but you can leave me a message.",
    "status_busy": "I'm busy but I'll respond when I can.",
    "status_invisible": "I prefer not to be seen at this time.",
    "nudge_sent": "Are you there?",
    "nudge_received": "Nudge sent (response stopped)",
    "nudge_stopped": "Response stopped",
    "voice_recording_started": "üé§ Recording... Speak now",
    "voice_recording_stopped": "üé§ Recording stopped",
    "file_attached": "Attached file: {filename}",
    "image_attached": "Image attached",
    "no_message": "no additional message",
    "image_processing": "Processing image...",
    "image_loaded": "Image loaded: {filename}",
    "image_pasted": "Image pasted successfully",
    "sending_large_file": "‚è≥ Sending complete file ({size}KB) to {count} models. Please wait, this may take several minutes...",
    "sending_file": "‚è≥ Sending complete file ({size}KB) to {count} models. Please wait...",
    "status_change_noticed": "I noticed your status change to {status}.",
    "status_change_noticed_help": "I noticed your status change to {status}. How can I help you?"
  },
  "errors": {
    "no_connection": "No connection to Ollama",
    "chat_not_found": "Chat not found",
    "server_error": "Server error: {status}",
    "verify_ollama": "Verify that Ollama is running.",
    "file_not_found": "File selector not found",
    "invalid_json": "Invalid JSON file or no chats.",
    "invalid_file": "Error reading file. Verify it's a valid JSON.",
    "select_file_first": "Please select a JSON file first",
    "select_valid_json": "Please select a valid JSON file",
    "only_txt_files": "Only .txt files are allowed",
    "text_file_too_large": "Text file is too large (maximum 100 MB)",
    "select_text_to_format": "Select text to format",
    "voice_not_supported": "Your browser does not support voice recognition.",
    "voice_error": "Voice recognition error",
    "voice_no_speech": "No voice detected. Please try again.",
    "voice_no_microphone": "Could not access microphone.",
    "voice_permission_denied": "Microphone permission denied.",
    "voice_network": "Network error in voice recognition.",
    "voice_network_connection": "‚ö†Ô∏è Connection error. Voice recognition requires internet. Check your connection and try again.",
    "voice_requires_internet": "‚ö†Ô∏è Voice recognition requires internet connection. Please connect and try again.",
    "voice_service_not_allowed": "Voice recognition service not available.",
    "voice_start_timeout": "‚ö†Ô∏è Could not connect to voice recognition service. Check your internet connection.",
    "voice_start_error": "Could not start voice recognition",
    "close_chat_confirm": "Close this chat and create a new one?",
    "only_pdf_files": "Only PDF files (.pdf) are allowed",
    "pdf_too_large": "PDF file is too large. Maximum allowed: 100 MB",
    "pdf_processing": "Processing PDF...",
    "pdf_extracting_text": "Extracting text from PDF...",
    "pdf_ocr_processing": "Applying OCR to PDF (this may take a while)...",
    "pdf_loaded": "PDF loaded: {filename}",
    "pdf_error": "Error processing PDF: {error}",
    "pdf_no_text": "Could not extract text from PDF. Try with a different file.",
    "pdf_attached": "PDF attached: {filename} ({pages} pages)",
    "select_chat_first": "Please select a chat first",
    "attachment_save_failed": "Error saving attachment",
    "delete_attachment_failed": "Error deleting attached file",
    "export_failed": "Error exporting chats",
    "import_failed": "Error importing chats",
    "download_file_failed": "Error downloading file",
    "only_image_files": "Only image files are allowed (JPG, PNG, GIF, WebP)",
    "image_too_large": "Image is too large. Maximum allowed: 20 MB",
    "image_error": "Error processing image: {error}",
    "model_no_image_support": "The selected AI model does not support image processing",
    "image_paste_failed": "Error pasting image",
    "expert_room_modal_error": "Error opening expert room modal",
    "no_models_for_room": "No models available to create a room"
  },
  "confirm": {
    "delete_attachment": "Delete this attachment?"
  },
  "connection": {
    "status": "Connection status:",
    "current_model": "Current model:",
    "no_models_available": "No models available",
    "model_not_available": "{model} (Not available)",
    "checking": "Checking connection to Ollama...",
    "server": "Server: {server}",
    "models_found": "Models found: {count}",
    "success": "Connection successful.",
    "failed": "Error connecting to Ollama"
  },
  "format": {
    "bold": "Bold",
    "italic": "Italic",
    "underline": "Underline"
  },
  "pdf": {
    "processing": "Processing PDF...",
    "extracting": "Extracting text...",
    "ocr_processing": "Applying OCR (page {current} of {total})...",
    "loaded": "PDF loaded successfully",
    "error": "Error processing PDF",
    "no_text": "Could not extract text from PDF",
    "too_large": "File too large (max. 100 MB)",
    "invalid_file": "Invalid PDF file",
    "pages": "pages",
    "attached": "PDF attached",
    "context_active": "PDF context active ({pages} pages)",
    "password_protected": "‚ùå The PDF file is password protected. Please remove the protection and try again.",
    "incorrect_password": "‚ùå Incorrect password for the protected PDF file.",
    "corrupted_file": "‚ùå The PDF file is corrupted or damaged. It cannot be processed.",
    "invalid_format": "‚ùå Invalid file format. Make sure it is a valid PDF file.",
    "empty_file": "‚ùå The PDF file is empty (0 pages).",
    "no_text_found": "‚ö†Ô∏è No extractable text found in the PDF. The document may be a scanned image without OCR.",
    "no_extractable_text": "‚ùå Could not extract any text from the PDF. Verify that the file contains readable text.",
    "processing_failed": "‚ùå Error processing the PDF file. The file may be corrupted or in an unsupported format.",
    "error_reading_file": "‚ùå Error reading the file. Verify that the file is not damaged.",
    "network_error": "üåê Network error while processing the PDF. Check your internet connection.",
    "ocr_not_available": "‚ùå The OCR engine is not available. Cannot process scanned PDFs.",
    "ocr_failed": "‚ùå OCR could not extract text from the PDF. The document may have very low-quality images."
  },
  "expert_room": {
    "title": "New Expert Room",
    "description": "Select the AI models that will participate in the expert room:",
    "room_name": "Room Name",
    "room_name_placeholder": "Expert Room",
    "default_name": "Expert Room",
    "select_min_models": "Please select at least 2 models",
    "created": "Room created with {count} experts",
    "models_label": "Experts",
    "model_error": "‚ö†Ô∏è Error querying {model}",
    "error_timeout": "‚è±Ô∏è {model}: The model is taking too long to respond. Please try again later.",
    "error_http_401": "üîê {model}: This model requires authentication. Please run 'ollama signin' in your terminal.",
    "error_http_429": "üö¶ {model}: Too many requests. The server is rate limiting requests. Please wait a moment before trying again.",
    "error_http_500": "‚ö†Ô∏è {model}: The server is experiencing problems. Try another model or try again later.",
    "error_http_404": "‚ùå {model}: This model is not currently available.",
    "error_http_503": "‚öôÔ∏è {model}: The service is under maintenance. Please try again later.",
    "error_network": "üåê {model}: Connection error. Please check your internet connection.",
    "error_generic": "‚ö†Ô∏è {model}: Unable to get a response at this time."
  }
}
