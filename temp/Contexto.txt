
✅ Servicios iniciados

� Estado de los contenedores:
NAME            IMAGE                  COMMAND                  SERVICE    CREATED         STATUS                            PORTS
msn-ai-app      docker-msn-ai          "/app/docker-entrypo…"   msn-ai     9 seconds ago   Up 3 seconds (health: starting)   0.0.0.0:8
000->8000/tcp, [::]:8000->8000/tcp
msn-ai-ollama   ollama/ollama:latest   "/bin/ollama serve"      ollama     9 seconds ago   Up 9 seconds (healthy)            0.0.0.0:1
1434->11434/tcp, [::]:11434->11434/tcp
msn-ai-setup    docker-ai-setup        "/bin/bash -c '/app/…"   ai-setup   9 seconds ago   Up 8 seconds (health: starting)   8000/tcp

✅ Contenedores Docker iniciados

failed to execute template: template: :1:19: executing "" at <.State.ExitCode>: can't evaluate field ExitCode in type string
⏳ Esperando que los servicios estén listos...

� Verificando servicio Ollama...
✅ Ollama está listo (intento 1/60)
� Verificando aplicación web MSN-AI...
✅ MSN-AI está listo (intento 5/60)

� Abriendo MSN-AI en el navegador...
� Abre manualmente: http://localhost:8000/msn-ai.html

� ¡MSN-AI Docker está ejecutándose!
====================================
� Verificando conectividad...
   � MSN-AI Web (localhost:8000): ✅ OK
   � Ollama API (localhost:11434): ✅ OK (0 modelos)

� URLs DE ACCESO:
   � Local:  http://localhost:8000/msn-ai.html
   � Remoto: http://192.168.1.106:8000/msn-ai.html

✅ MSN-AI COMPLETAMENTE FUNCIONAL
   • Interfaz web accesible
   • API Ollama respondiendo
   • 0 modelos disponibles
   • Auto-detección de configuración habilitada
   • Sin configuración de firewall requerida

� Contenedores:
NAME            IMAGE                  COMMAND                  SERVICE    CREATED          STATUS                             PORTS
msn-ai-app      docker-msn-ai          "/app/docker-entrypo…"   msn-ai     23 seconds ago   Up 16 seconds (healthy)            0.0.0.0
:8000->8000/tcp, [::]:8000->8000/tcp
msn-ai-ollama   ollama/ollama:latest   "/bin/ollama serve"      ollama     23 seconds ago   Up 22 seconds (healthy)            0.0.0.0
:11434->11434/tcp, [::]:11434->11434/tcp
msn-ai-setup    docker-ai-setup        "/bin/bash -c '/app/…"   ai-setup   23 seconds ago   Up 21 seconds (health: starting)   8000/tc
p

� Estado de servicios:
NAME            STATUS                             PORTS
msn-ai-app      Up 17 seconds (healthy)            0.0.0.0:8000->8000/tcp, [::]:8000->8000/tcp
msn-ai-ollama   Up 23 seconds (healthy)            0.0.0.0:11434->11434/tcp, [::]:11434->11434/tcp
msn-ai-setup    Up 22 seconds (health: starting)   8000/tcp

� Comandos útiles:
   � Ver logs:        docker compose -f docker/docker-compose.yml logs -f
   ⏹️  Detener:         docker compose -f docker/docker-compose.yml down
   � Reiniciar:       docker compose -f docker/docker-compose.yml restart
   � Estado:          docker compose -f docker/docker-compose.yml ps

⚠️  DETENCIÓN CORRECTA:
   docker compose -f docker/docker-compose.yml down

� Datos persistentes en volumes de Docker
� Soporte: alan.mac.arthur.garcia.diaz@gmail.com

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
☁️  MODELOS CLOUD DISPONIBLES
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

Los siguientes modelos cloud requieren autenticación:
  � qwen3-vl:235b-cloud
  � gpt-oss:120b-cloud
  � qwen3-coder:480b-cloud

⚠️  Los modelos cloud NO se instalan automáticamente

� Para instalar modelos cloud:

1️⃣  Accede al contenedor:
   docker exec -it msn-ai-ollama /bin/bash

2️⃣  Haz signin (abre el enlace generado en tu navegador):
   ollama signin

3️⃣  Instala los modelos que necesites:
   ollama pull qwen3-vl:235b-cloud
   ollama pull gpt-oss:120b-cloud
   ollama pull qwen3-coder:480b-cloud

4️⃣  Verifica la instalación:
   ollama list

5️⃣  Sal del contenedor:
   exit

� Los modelos locales ya están instalados y funcionando
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
� Script completado. Los contenedores continúan ejecutándose.
   Para detenerlos: docker compose -f docker/docker-compose.yml down
root@qtserverdev:/home/server/MSN-AI# ls
assets        docker  LICENSE  macos         msn-ai.html  README.md         start-docker.sh  start.sh    temp
CHANGELOG.md  lang    linux    MIGRATION.md  msn-ai.js    start-docker.ps1  start.ps1        styles.css  windows
root@qtserverdev:/home/server/MSN-AI# cd linux/
root@qtserverdev:/home/server/MSN-AI/linux# ls
ai_check_all.sh             docker-cleanup.sh               docker-start-debug.sh  docker-test-ai.sh      test-msnai.sh
configure-api-key.sh        docker-diagnostics.sh           docker-start.sh        README.md
create-desktop-shortcut.sh  docker-install-cloud-models.sh  docker-status.sh       start-msnai-docker.sh
docker-check-config.sh      docker-logs.sh                  docker-stop.sh         start-msnai.sh
root@qtserverdev:/home/server/MSN-AI/linux# ./docker-install-cloud-models.sh
☁️  MSN-AI - Instalador de Modelos Cloud
==========================================
� Desarrollado por: Alan Mac-Arthur García Díaz
⚖️ Licencia: GPL-3.0
==========================================

✅ Contenedor msn-ai-ollama detectado

� Modelos cloud disponibles:
   1. qwen3-vl:235b-cloud
   2. gpt-oss:120b-cloud
   3. qwen3-coder:480b-cloud

� Verificando estado de autenticación...
✅ Ya has hecho signin con Ollama

� Verificando modelos instalados...

   ⏭️  qwen3-vl:235b-cloud (no instalado)
   ⏭️  gpt-oss:120b-cloud (no instalado)
   ⏭️  qwen3-coder:480b-cloud (no instalado)

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
� INSTALACIÓN DE MODELOS
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

¿Qué deseas instalar?

1) Instalar todos los modelos cloud
2) Instalar modelos individuales
3) Solo verificar modelos instalados
4) Salir

Selecciona una opción (1-4): 1

� Instalando todos los modelos cloud...

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
� Instalando: qwen3-vl:235b-cloud
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

pulling manifest
pulling 30592ae5763b: 100% ▕██████████████████▏  384 B
verifying sha256 digest
writing manifest
success

✅ qwen3-vl:235b-cloud instalado correctamente

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
� Instalando: gpt-oss:120b-cloud
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

pulling manifest
pulling 923426e76b18: 100% ▕██████████████████▏  384 B
verifying sha256 digest
writing manifest
success

✅ gpt-oss:120b-cloud instalado correctamente

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
� Instalando: qwen3-coder:480b-cloud
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

pulling manifest
pulling 476b4620b85b: 100% ▕██████████████████▏  382 B
verifying sha256 digest
writing manifest
success

✅ qwen3-coder:480b-cloud instalado correctamente


━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
� ESTADO FINAL
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

Modelos instalados:
NAME                      ID              SIZE      MODIFIED
qwen3-coder:480b-cloud    e30e45586389    -         Less than a second ago
gpt-oss:120b-cloud        569662207105    -         3 seconds ago
qwen3-vl:235b-cloud       7fc468f95411    -         6 seconds ago
tinyllama:latest          2644915ede35    637 MB    2 minutes ago

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
✅ Proceso completado
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

� Los modelos cloud ahora están disponibles en MSN-AI

� Accede a MSN-AI en: http://localhost:8000/msn-ai.html

root@qtserverdev:/home/server/MSN-AI/linux# docker exec -it msn-ai-ollama /bin/bash
root@864d07d8489c:/# ollama signin
You need to be signed in to Ollama to run Cloud models.

To sign in, navigate to:
    https://ollama.com/connect?name=864d07d8489c&key=c3NoLWVkMjU1MTkgQUFBQUMzTnphQzFsWkRJMU5URTVBQUFBSUNGRk1DQVplZWVlL2FlY1pRUG9FMUdKa
URjVGM1ZmFqRWxUeCtWUmdDdmk

root@864d07d8489c:/#
