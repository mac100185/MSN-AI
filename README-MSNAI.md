# MSN-AI - Windows Live Messenger con IA Local

![MSN-AI Logo](assets/general/logo.png)

**Versi√≥n 1.0.0** | **Licencia GPL-3.0** | **Por Alan Mac-Arthur Garc√≠a D√≠az**

## üéØ Descripci√≥n

MSN-AI es una aplicaci√≥n web que combina la nost√°lgica interfaz de Windows Live Messenger 8.5 con la potencia de los modelos de IA local ejecutados a trav√©s de Ollama. Disfruta de la experiencia cl√°sica de MSN mientras conversas con asistentes de inteligencia artificial avanzados.

**Desarrollado por**: Alan Mac-Arthur Garc√≠a D√≠az  
**Contacto**: [alan.mac.arthur.garcia.diaz@gmail.com](mailto:alan.mac.arthur.garcia.diaz@gmail.com)  
**Licencia**: GNU General Public License v3.0

## ‚ú® Caracter√≠sticas principales

### üé® Interfaz aut√©ntica
- Recreaci√≥n pixel-perfect de Windows Live Messenger 8.5
- Sonidos aut√©nticos del MSN original
- Efectos visuales Aero fieles al original
- Scrollbars personalizados estilo Windows Vista/7

### ü§ñ IA integrada
- Soporte para m√∫ltiples modelos de IA (Mistral, Llama, Phi3, etc.)
- Conversaciones contextuales inteligentes
- Detecci√≥n autom√°tica de modelos disponibles
- Reconexi√≥n autom√°tica con Ollama

### üíæ Gesti√≥n de datos
- Almacenamiento local en el navegador (localStorage)
- Historial completo de conversaciones
- Sistema de b√∫squeda en chats
- Exportaci√≥n e importaci√≥n de chats en JSON

### üîä Experiencia inmersiva
- Sonidos aut√©nticos de MSN (login, mensajes, notificaciones)
- Indicadores visuales de estado de conexi√≥n
- Animaciones de "IA pensando"
- Interfaz completamente responsive

## üöÄ Instalaci√≥n y configuraci√≥n

### Prerrequisitos

1. **Ollama instalado y ejecut√°ndose**
   - Descargar desde: https://ollama.ai
   - O usar el script incluido: `./ai_check_all.sh`

2. **Al menos un modelo de IA descargado**
   ```bash
   ollama pull mistral:7b  # Recomendado para empezar
   ollama pull llama3:8b   # Para mejor rendimiento
   ollama pull phi3:mini   # Para equipos limitados
   ```

### Uso r√°pido

1. **Abrir el archivo**
   ```bash
   # Opci√≥n 1: Navegador web
   firefox MSN-AI/msn-ai.html
   
   # Opci√≥n 2: Servidor local simple
   python3 -m http.server 8000
   # Luego abrir: http://localhost:8000/MSN-AI/msn-ai.html
   ```

2. **Verificar conexi√≥n**
   - Al iniciar, MSN-AI intentar√° conectarse autom√°ticamente a Ollama
   - Indicador de estado en la esquina inferior derecha
   - Verde = Conectado, Rojo = Desconectado, Amarillo = Conectando

3. **Comenzar a chatear**
   - Clic en "Nuevo Chat" para crear una conversaci√≥n
   - Escribe tu mensaje y presiona Enter o clic en "Enviar"
   ### 3. ¬°Disfruta de la nostalgia mientras conversas con IA!

   ## ‚èπÔ∏è Detener MSN-AI correctamente

   **‚ö†Ô∏è IMPORTANTE**: Siempre det√©n correctamente para evitar da√±os al sistema:

   ### M√©todo recomendado
   ```bash
   # En la terminal donde ejecutaste start-msnai.sh:
   Ctrl + C
   # El script autom√°ticamente limpiar√° todos los procesos
   ```

   ### Detenci√≥n manual (emergencia)
   ```bash
   # Detener todos los procesos relacionados
   pkill -f "python.*http.server"
   pkill -f "http-server" 
   pkill -f "start-msnai"
   pkill ollama  # Solo si fue iniciado por el script

   # Verificar que todo est√© detenido
   ps aux | grep -E "(python.*http|ollama|start-msnai)"
   ```

   ### Indicadores de detenci√≥n exitosa
   - ‚úÖ Mensaje: "üëã ¬°Gracias por usar MSN-AI!"
   - ‚úÖ Puerto 8000 liberado (no responde)
   - ‚úÖ Sin procesos relacionados ejecut√°ndose
   - ‚úÖ Terminal disponible para nuevos comandos

   ### ‚ùå Nunca hagas esto
   - Cerrar terminal sin Ctrl+C
   - Usar `kill -9` directamente
   - Apagar el sistema con servicios activos
   - Forzar cierre del navegador sin detener servicios

   ## üìö Gu√≠a de uso

### Gesti√≥n de chats

#### Crear nuevo chat
- Clic en el bot√≥n con icono "+" en la barra de navegaci√≥n
- Se crear√° autom√°ticamente con el modelo seleccionado
- El t√≠tulo se genera autom√°ticamente basado en el primer mensaje

#### Seleccionar chat
- Clic en cualquier chat de la lista izquierda
- El chat activo se resalta en azul
- Los mensajes se cargan autom√°ticamente

#### Buscar chats
- Usar la barra de b√∫squeda superior
- Busca en t√≠tulos y contenido de mensajes
- Filtrado en tiempo real

#### Eliminar chat
- Clic derecho sobre un chat ‚Üí Confirmar eliminaci√≥n
- **‚ö†Ô∏è Acci√≥n irreversible**

### Configuraci√≥n

#### Acceder a configuraci√≥n
- Clic en el bot√≥n de engranaje (esquina superior derecha)

#### Opciones disponibles
- **Sonidos**: Activar/desactivar efectos de sonido
- **Servidor Ollama**: Cambiar URL del servidor (por defecto: `http://localhost:11434`)
- **Modelo de IA**: Seleccionar modelo preferido para nuevos chats
- **Probar conexi√≥n**: Verificar conectividad con Ollama

### Import/Export

#### Exportar chats
1. Clic en bot√≥n de exportar (icono de carpeta)
2. Se descarga autom√°ticamente un archivo JSON
3. Formato: `msn-ai-chats-YYYY-MM-DD.json`

#### Importar chats
1. Clic en bot√≥n de importar
2. Seleccionar archivo JSON previamente exportado
3. Los chats se agregan a los existentes (no se sobrescriben)

#### Estructura del archivo JSON
```json
{
  "version": "1.0",
  "exportDate": "2025-01-07T10:30:00.000Z",
  "chats": [
    {
      "id": "chat-1704625800000",
      "title": "Consulta sobre JavaScript",
      "date": "2025-01-07T10:30:00.000Z",
      "model": "mistral:7b",
      "messages": [
        {
          "type": "user",
          "content": "¬øC√≥mo funciona async/await?",
          "timestamp": "2025-01-07T10:30:00.000Z"
        },
        {
          "type": "ai",
          "content": "async/await es una sintaxis...",
          "timestamp": "2025-01-07T10:30:15.000Z"
        }
      ]
    }
  ],
  "settings": {
    "soundsEnabled": true,
    "ollamaServer": "http://localhost:11434",
    "selectedModel": "mistral:7b"
  }
}
```

## üéµ Sonidos incluidos

| Archivo | Descripci√≥n | Cu√°ndo se reproduce |
|---------|-------------|-------------------|
| `login.wav` | Sonido de inicio de MSN | Al cargar la aplicaci√≥n y al importar |
| `message_in.wav` | Mensaje recibido | Cuando la IA responde |
| `message_out.wav` | Mensaje enviado | Al enviar tu mensaje |
| `nudge.wav` | Zumbido/notificaci√≥n | Al crear nuevo chat y exportar |
| `calling.wav` | Sonido de llamada | Futuras funcionalidades |

## ‚öôÔ∏è Configuraci√≥n avanzada

### Modelos recomendados seg√∫n hardware

| Hardware | Modelo recomendado | Raz√≥n |
|----------|-------------------|--------|
| 80GB+ VRAM | `llama3:70b` | M√°ximo rendimiento |
| 24GB+ VRAM | `llama3:8b` | Excelente para programaci√≥n |
| 8-16GB VRAM | `mistral:7b` | Balance perfecto |
| Solo CPU, 32GB+ RAM | `mistral:7b` | Funciona en CPU |
| Hardware limitado | `phi3:mini` | Ligero y eficiente |

### Personalizaci√≥n del servidor Ollama

```bash
# Cambiar puerto por defecto
OLLAMA_HOST=0.0.0.0:11435 ollama serve

# Configurar GPU espec√≠fica
CUDA_VISIBLE_DEVICES=0 ollama serve

# Configurar memoria l√≠mite
OLLAMA_GPU_MEMORY_FRACTION=0.8 ollama serve
```

### Configuraci√≥n de red

Si Ollama est√° en otro servidor:
1. Ir a Configuraci√≥n
2. Cambiar "Servidor Ollama" a: `http://IP_SERVIDOR:11434`
3. Asegurar que Ollama permita conexiones externas:
   ```bash
   OLLAMA_HOST=0.0.0.0:11434 ollama serve
   ```

## üîß Soluci√≥n de problemas

### Error: "No hay conexi√≥n con Ollama"
**Causa**: Ollama no est√° ejecut√°ndose o no es accesible
**Soluci√≥n**:
1. Verificar que Ollama est√© ejecut√°ndose: `ollama list`
2. Verificar el puerto: `netstat -tlnp | grep 11434`
3. Probar conexi√≥n manual: `curl http://localhost:11434/api/tags`

### Error: "Modelo no disponible"
**Causa**: El modelo seleccionado no est√° descargado
**Soluci√≥n**:
1. Listar modelos disponibles: `ollama list`
2. Descargar modelo: `ollama pull mistral:7b`
3. Reiniciar MSN-AI

### Los sonidos no se reproducen
**Causa**: Navegador bloquea autoplay o archivos no encontrados
**Soluci√≥n**:
1. Permitir autoplay en el navegador
2. Verificar que existan los archivos en `assets/sounds/`
3. Desactivar/activar sonidos en Configuraci√≥n

### Chat lento o no responde
**Causa**: Modelo muy grande para el hardware o problemas de red
**Soluci√≥n**:
1. Cambiar a modelo m√°s ligero (phi3:mini)
2. Verificar uso de GPU: `nvidia-smi`
3. Verificar log de Ollama: `journalctl -u ollama`

### P√©rdida de datos
**Causa**: localStorage del navegador fue limpiado
**Soluci√≥n**:
1. Los datos se guardan autom√°ticamente en localStorage
2. Exportar regularmente los chats como respaldo
3. Importar desde archivo JSON de respaldo

## üé® Caracter√≠sticas t√©cnicas

### Tecnolog√≠as utilizadas
- **Frontend**: HTML5, CSS3, JavaScript ES6+
- **Almacenamiento**: LocalStorage API
- **IA**: Ollama REST API
- **Audio**: Web Audio API
- **Estilo**: CSS Grid y Flexbox

### Compatibilidad de navegadores
- ‚úÖ Chrome 80+
- ‚úÖ Firefox 75+
- ‚úÖ Safari 14+
- ‚úÖ Edge 80+
- ‚ö†Ô∏è Internet Explorer: No soportado

### Tama√±o de la aplicaci√≥n
- **Archivo principal**: ~50KB (msn-ai.html)
- **Assets totales**: ~2MB (im√°genes y sonidos)
- **Almacenamiento usado**: Variable seg√∫n chats guardados

### Rendimiento
- **Carga inicial**: <2 segundos
- **Renderizado de mensajes**: <100ms
- **Respuesta de IA**: Depende del modelo y hardware
- **Uso de memoria**: ~20-50MB t√≠pico

## üìñ API de desarrollo

### Clase principal: MSNAI

```javascript
// Crear nueva instancia
const msnai = new MSNAI();

// Crear chat program√°ticamente
const chatId = msnai.createNewChat();

// Enviar mensaje program√°ticamente
await msnai.sendMessage('Hola IA', chatId);

// Exportar datos
const data = msnai.exportChats();

// Cambiar configuraci√≥n
msnai.settings.selectedModel = 'llama3:8b';
msnai.saveSettings();
```

### Eventos disponibles

```javascript
// Escuchar conexi√≥n con Ollama
msnai.on('connection', (status) => {
    console.log('Estado de conexi√≥n:', status);
});

// Escuchar nuevos mensajes
msnai.on('message', (message) => {
    console.log('Nuevo mensaje:', message);
});
```

## ü§ù Contribuci√≥n

### Estructura del proyecto
```
MSN-AI/
‚îú‚îÄ‚îÄ msn-ai.html          # Aplicaci√≥n principal (todo en uno)
‚îú‚îÄ‚îÄ ai_check_all.sh      # Script de detecci√≥n de hardware
‚îú‚îÄ‚îÄ backup/              # Respaldos de archivos originales
‚îú‚îÄ‚îÄ assets/              # Recursos multimedia
‚îÇ   ‚îú‚îÄ‚îÄ sounds/          # Efectos de sonido
‚îÇ   ‚îú‚îÄ‚îÄ background/      # Im√°genes de fondo
‚îÇ   ‚îú‚îÄ‚îÄ chat-window/     # Iconos de chat
‚îÇ   ‚îú‚îÄ‚îÄ contacts-window/ # Iconos de contactos
‚îÇ   ‚îú‚îÄ‚îÄ general/         # Elementos generales
‚îÇ   ‚îú‚îÄ‚îÄ scrollbar/       # Elementos de scrollbar
‚îÇ   ‚îî‚îÄ‚îÄ status/          # Iconos de estado
‚îî‚îÄ‚îÄ README-MSNAI.md      # Esta documentaci√≥n
```

### C√≥mo contribuir
1. Fork del repositorio
2. Crear rama feature: `git checkout -b feature/nueva-funcionalidad`
3. Commit cambios: `git commit -am 'Agregar nueva funcionalidad'`
4. Push a la rama: `git push origin feature/nueva-funcionalidad`
5. Crear Pull Request

### Roadmap
- [ ] Soporte para m√°s modelos de IA (Claude, GPT local)
- [ ] Sistema de plugins para extensiones
- [ ] Temas personalizables
- [ ] Integraci√≥n con servicios de nube
- [ ] App m√≥vil h√≠brida
- [ ] Cifrado end-to-end para chats
- [ ] Colaboraci√≥n en tiempo real
- [ ] Integraci√≥n con Escargot/MSN servers

## üìÑ Licencia y T√©rminos Legales

### ‚öñÔ∏è Licencia Principal
Este proyecto est√° licenciado bajo la **GNU General Public License v3.0**.

**Puntos clave de GPL-3.0:**
- ‚úÖ Libertad de usar para cualquier prop√≥sito
- ‚úÖ Libertad de estudiar y modificar el c√≥digo
- ‚úÖ Libertad de distribuir copias  
- ‚úÖ Libertad de distribuir modificaciones
- ‚öñÔ∏è Copyleft: Las modificaciones deben ser GPL-3.0 tambi√©n

Ver el archivo [LICENSE](LICENSE) para el texto completo.

### üõ°Ô∏è Garant√≠a y Responsabilidad
**SOFTWARE PROPORCIONADO "TAL COMO EST√Å"** seg√∫n GPL-3.0:
- ‚ùå Sin garant√≠a de funcionamiento
- ‚ùå Sin garant√≠a de compatibilidad
- ‚ùå Sin responsabilidad por da√±os
- ‚úÖ C√≥digo abierto para auditor√≠a completa
- ‚úÖ Soporte de mejor esfuerzo de la comunidad

### üìú Derechos de Terceros
- **Assets de Microsoft**: Usados bajo Fair Use para preservaci√≥n hist√≥rica
- **Sonidos originales**: Extra√≠dos para fines educativos
- **Proyecto base WLMOnline**: Por androidWG, respetando licencia original
- **Ollama**: Software independiente con su propia licencia

### üîí Pol√≠tica de Privacidad
- **100% Local**: Sin env√≠o de datos a servidores externos
- **Sin rastreo**: No recopilamos informaci√≥n personal
- **LocalStorage √∫nicamente**: Datos almacenados en tu navegador
- **Control total**: Exporta, importa o elimina tus datos cuando quieras

## üôè Agradecimientos

- **androidWG** por el proyecto original [WLMOnline](https://github.com/androidWG/WLMOnline)
- **Microsoft Corporation** por Windows Live Messenger original
- **Ollama** por hacer accesible la IA local
- **Escargot Project** por mantener vivos los servidores de MSN
- **Messenger Plus!** por las herramientas de extracci√≥n de assets
- **Comunidad Open Source** por las librer√≠as y herramientas utilizadas

## üìû Soporte y Contacto

### üë®‚Äçüíª Desarrollador
**Alan Mac-Arthur Garc√≠a D√≠az**  
üìß **Email**: [alan.mac.arthur.garcia.diaz@gmail.com](mailto:alan.mac.arthur.garcia.diaz@gmail.com)

### üÜò Obtener ayuda
¬øNecesitas ayuda? ¬øEncontraste un bug? ¬øTienes una idea genial?

- üêõ **GitHub Issues**: Para reportes de bugs y solicitudes de funcionalidades
- üí¨ **Discusiones**: Para preguntas y sugerencias generales  
- üìß **Email directo**: Para soporte t√©cnico urgente
- ü§ù **Comunidad**: Los usuarios se ayudan entre s√≠

### ‚è±Ô∏è Tiempo de respuesta
- **Issues cr√≠ticos**: Mejor esfuerzo, sin garant√≠a de SLA
- **Preguntas generales**: Respuesta cuando sea posible
- **Contribuciones**: Revisi√≥n activa de Pull Requests
- **Email directo**: Para casos urgentes √∫nicamente

### ü§ù C√≥digo de conducta
- Respeta a otros usuarios y colaboradores
- Proporciona informaci√≥n detallada en reportes
- S√© constructivo en cr√≠ticas y sugerencias
- Mant√©n las discusiones on-topic

---

## üîó Enlaces importantes

- üìñ **Documentaci√≥n**: [README.md](README.md) - Gu√≠a principal  
- üìã **Cambios**: [CHANGELOG.md](CHANGELOG.md) - Historial de versiones
- ‚öñÔ∏è **Licencia**: [LICENSE](LICENSE) - Texto completo GPL-3.0
- üè† **Proyecto base**: [WLMOnline](https://github.com/androidWG/WLMOnline)

---

**¬°Disfruta de la nostalgia con el poder de la IA moderna! üöÄ‚ú®**

*MSN-AI v1.0.0 - Donde el pasado se encuentra con el futuro*

**Desarrollado con ‚ù§Ô∏è por Alan Mac-Arthur Garc√≠a D√≠az**  
**Licenciado bajo GPL-3.0 | Enero 2025**